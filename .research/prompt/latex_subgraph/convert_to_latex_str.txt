
Input:

You are a LaTeX expert.
Your task is to convert each section of a research paper into plain LaTeX **content only**, without including any section titles or metadata.

Below are the paper sections. For each one, convert only the **content** into LaTeX:

---
Section: title

Stability-Aware Curve Compression for Bayesian Optimisation of Deep Reinforcement-Learning Hyper-parameters

---

---
Section: abstract

Bayesian Optimisation for Iterative Learning (BOIL) compresses an entire learning curve into a single scalar through a sigmoid-weighted average that a Gaussian Process (GP) can model. While this summary accelerates hyper-parameter search, it ignores late-stage oscillations that are commonplace in deep reinforcement learning (RL). Consequently, BOIL may repeatedly invest evaluations in hyper-parameters that spike to high returns yet produce brittle policies. We propose Stability-Aware Curve Compression (SACC), a drop-in replacement for BOIL’s scoring function that subtracts a stability penalty from the original score: s = m(curve) – λ · std(tail), where m(curve) is the sigmoid-weighted mean, std(tail) is the standard deviation of the last K % of episodes and λ ≥ 0 is a learnable coefficient. The amendment preserves BOIL’s one-dimensional interface, adds three lines of code, and introduces a single additional parameter that is learned jointly with BOIL’s logistic midpoint and growth by maximising GP log-marginal likelihood. On classic control and MuJoCo benchmarks SACC, evaluated over 10 random seeds, reduces the number of BO evaluations needed to reach task success by 22–31 %, raises best-of-run returns by 5–14 %, lowers evaluation-phase reward variance by roughly 30 %, and increases wall-clock cost by less than 2 %. These results show that penalising tail volatility guides Bayesian optimisation toward robust hyper-parameters without sacrificing sample efficiency.

---

---
Section: introduction

Hyper-parameter optimisation (HPO) remains a principal bottleneck in deep reinforcement learning because each evaluation entails thousands of expensive, high-variance environment interactions. Bayesian optimisation (BO) is attractive in this regime, but most BO variants treat performance as a terminal scalar, wasting information available in the trajectory of rewards accrued during training. Bayesian Optimisation for Iterative Learning (BOIL) alleviates this inefficiency by compressing partial learning curves into a scalar via a sigmoid-weighted average, allowing the GP surrogate and acquisition function to exploit intermediate progress \cite{nguyen-2019-bayesian}. Unfortunately, a sole mean-like statistic hides a critical facet of solution quality: stability. Learning curves that climb to high rewards but oscillate heavily toward the end of training are unreliable at test time, yet BOIL, blind to volatility, may continue to query such regions of hyper-parameter space.

We address this reliability gap with Stability-Aware Curve Compression (SACC), a minimal modification of BOIL that rewards both progress and steadiness. After computing BOIL’s sigmoid-weighted mean m(curve), SACC subtracts a penalty proportional to the standard deviation of the last K % of episodes, producing a new score s = m – λ · σ_tail. The penalty strength λ is appended to BOIL’s compression parameters and learned through GP marginal-likelihood maximisation, so no hand-tuning is required. Crucially, the score remains one-dimensional, leaving BOIL’s surrogate, data augmentation, and acquisition optimisation intact.

Why is designing such a penalty hard? (i) Inflating the surrogate’s output dimensionality would forfeit BOIL’s computational advantage. (ii) Stability must be assessed cheaply because environment steps dominate cost. (iii) The penalty must adapt across tasks with disparate reward scales and noise characteristics. SACC satisfies these constraints by reusing BOIL’s interface, computing one additional standard deviation, and letting λ adjust automatically.

We empirically evaluate SACC on classic control tasks (CartPole-v1, LunarLander-v2, Acrobot-v1) and stochastic MuJoCo tasks (Hopper-v3, HalfCheetah-v3) under a unified protocol that measures five axes: sample efficiency, performance ceiling, stability, computational overhead, and generalisation. Baselines include vanilla BOIL \cite{nguyen-2019-bayesian}, fixed-λ ablations, and external HPO approaches such as multi-fidelity bandits and tree-structured Parzen estimators. Partition-based hyper-parameter optimisation methods that bypass BO surrogates \cite{mlodozeniec-2023-hyperparameter} are also discussed for contrast but are not directly comparable because they neither exploit full curves nor target volatility.

Contributions
• We uncover a reliability blind spot in BOIL and introduce SACC, a three-line drop-in fix that maintains BOIL’s one-dimensional surrogate.
• We integrate λ as a learnable compression parameter, enabling task-adaptive stability control without manual tuning.
• We present a rigorous, reusable evaluation protocol focusing on efficiency, robustness, and cost.
• Across six benchmarks and multiple noise regimes, we demonstrate 22–31 % faster convergence, 5–14 % higher best returns, ≈30 % lower policy variance, and <2 % runtime overhead.

Future work can extend SACC to richer one-dimensional robustness proxies, dynamic tail fractions, and hybrid schemes that blend curve compression with partition-based objectives.

---

---
Section: related_work

Bayesian optimisation for hyper-parameter tuning traditionally relies on endpoint performance only. BOIL broke with this tradition by using a learnable sigmoid to weight intermediate rewards, markedly improving sample efficiency in neural network and RL settings \cite{nguyen-2019-bayesian}. Our work adheres to BOIL’s curve-centric philosophy but argues that a mean-style statistic is insufficient when late-stage volatility jeopardises policy reliability. By attaching an adaptive variance penalty, SACC retains BOIL’s machinery while explicitly discouraging oscillatory trajectories.

Hyperparameter Optimisation through Neural Network Partitioning (HPO-NP) introduces a fundamentally different idea: optimise hyper-parameters via marginal-likelihood-inspired losses computed on subnetworks trained on data shards, eliminating the need for separate validation sets \cite{mlodozeniec-2023-hyperparameter}. While effective for supervised learning, HPO-NP neither models the entire learning curve nor targets stability, and its reliance on differentiable objectives limits direct applicability to RL with sparse, delayed rewards.

Alternative BO extensions include multi-fidelity methods that terminate unpromising runs early, density-estimation techniques such as TPE, and population-based bandits. These algorithms do not encode volatility awareness; any stability benefit is incidental. Empirically, our experiments show that such baselines trail BOIL+SACC in both sample efficiency and reward variance, highlighting the value of explicit stability awareness.

Compared to prior work, SACC is unique in providing (i) a negligible-cost stability proxy that (ii) preserves the scalar surrogate interface and (iii) adapts automatically through GP marginal-likelihood learning, thereby offering a pragmatic and theoretically consistent refinement of curve-aware BO.

---

---
Section: background

Problem setting. Let x ∈ X denote a hyper-parameter vector; training an agent under x for T episodes yields a reward sequence r₁:T. We seek to minimise the number of costly evaluations of f(x) while discovering x values whose induced policies achieve high, stable returns. BOIL defines f(x) as a sigmoid-weighted mean m(x)=1/T Σ_t w_t r_t, where weights w_t depend on learnable midpoint μ and growth g parameters of a logistic. A Gaussian Process prior over f and an acquisition function then drive sequential search \cite{nguyen-2019-bayesian}.

Limitation of BOIL. Because m(x) is essentially an average, it conflates smooth and erratic curves that share similar central tendencies. In deep RL, however, volatility often signals over-fitting to transient dynamics or premature value-function divergence—issues that manifest as poor generalisation or catastrophic drops once exploration noise is removed.

Stability proxy. We posit that the standard deviation of the tail—defined as the last ⌈K·T⌉ episodes—is an inexpensive yet informative measure of policy reliability. Using only the tail focuses on the period closest to deployment, ignoring early-phase exploration noise.

Design principles. (i) One-dimensional compression keeps BOIL’s computational benefits. (ii) Penalty computation must not require gradient access to the RL algorithm. (iii) The penalty weight λ should be data-driven because reward scales vary by environment (CartPole ≈200 vs HalfCheetah >10,000). SACC satisfies these principles by computing σ_tail from logged rewards and learning λ via GP marginal likelihood alongside μ and g.

---

---
Section: method

Given a reward trajectory r₁:T, BOIL first maps episode indices to a scaled axis and computes weights w_t = 1/(1+exp(−g (s_t − μ))). The original score is m = (1/T) Σ_t w_t r_t. Stability-Aware Curve Compression augments this by
1. Selecting the tail: k = max(1, ⌈K·T⌉). Tail rewards are r_{T−k+1:T}.
2. Computing volatility: σ_tail = std(r_{T−k+1:T}).
3. Producing the score: s = m − λ σ_tail, with λ ≥ 0.

Algorithmic integration. We simply replace BOIL’s apply_one_transform_logistic with a three-line variant:
   m = original_sigmoid_mean(curve)
   σ = np.std(curve)
   return m − λ·σ

Parameter learning. The vector θ = (μ, g, λ) maximises the GP log-marginal likelihood over observed pairs (x_i, s_i). We bound λ to  and initialise at 1.0. Acquisition, data augmentation across partial curves, and GP kernel choices remain identical to BOIL.

Computational overhead. σ_tail uses at most k additional floating-point operations per evaluation—negligible relative to millions of environment steps. Because s remains scalar, GP regression complexity is unchanged.

---

---
Section: experimental_setup

Unified protocol. To facilitate fair comparison and future replication, we employ a standardised five-step procedure: (1) Fix task-specific success thresholds and hyper-parameter search spaces. (2) Generate an identical random initial design of five configurations for all methods. (3) Run BO for a fixed budget B evaluations (25 for classic control, 40 for MuJoCo), logging full learning curves. (4) Retrain the best configuration from each run for an extended horizon, collecting 20–50 evaluation episodes. (5) Aggregate metrics across 10 random seeds (8 for MuJoCo) and conduct paired statistical tests.

Tasks and search spaces. Classic control (CartPole-v1, LunarLander-v2, Acrobot-v1) tune two DQN hyper-parameters: learning rate and target-network update period. MuJoCo tasks (Hopper-v3, HalfCheetah-v3) extend the space to up to seven parameters, adding optimiser momentum, exploration ε, and discount γ.

Methods. We compare (i) vanilla BOIL \cite{nguyen-2019-bayesian}; (ii) BOIL+SACC (ours); (iii) fixed-λ ablations (λ∈{0.5,1,2,4}); (iv) multi-fidelity Asynchronous Successive Halving (ASHA); (v) Tree-Structured Parzen Estimator (TPE). All methods share the same RL implementation, seeds, and hardware.

Hyper-parameters for SACC. Tail fraction K = 0.10 by default; sensitivity analysis tests K = 0.20. λ is learned with bounds . All other GP and acquisition settings mirror BOIL defaults.

Metrics. Primary: (1) evaluations-to-threshold; (2) best validation reward after B evaluations. Secondary: (3) area under the best-return curve; (4) σ_tail; (5) evaluation-phase reward mean ± std; (6) wall-clock and memory usage. Significance is assessed with paired t-tests or Wilcoxon tests at p < 0.05.

---

---
Section: results

Main study (classic control). BOIL+SACC reaches the success threshold in fewer evaluations: CartPole-v1 12.1 ± 1.0 vs 17.3 ± 1.2 for BOIL (−30 %, p=8×10⁻⁴); LunarLander-v2 16.2 ± 1.3 vs 21.6 ± 1.5 (−25 %, p=3×10⁻³); Acrobot-v1 14.0 ± 1.1 vs 19.4 ± 1.4 (−28 %, p=2×10⁻³). Best-of-run returns improve by 3–5 % (CartPole +6.6, LunarLander +11.4, Acrobot +13.2). Training-curve volatility falls by 31 % on average; evaluation-phase reward std drops by 51 % (CartPole) and 33 % (LunarLander). Area-under-curve gains average 21 %.

Robustness study (MuJoCo, high variance). With a 40-evaluation budget, SACC outpaces BOIL: Hopper-v3 threshold at 28.2 vs 36.1 evaluations (−22 %, p=0.01); HalfCheetah-v3 29.4 vs 37.2 (−21 %, p=0.02). Best-of-run returns rise by ≈5 %. Evaluation-phase std decreases by 31 % (Hopper) and 28 % (HalfCheetah). Under gravity-shift stress, SACC’s performance degrades by 12 % vs 22 % for BOIL.

Ablations. Fixed-λ variants outperform vanilla BOIL but underperform learned-λ SACC on all primary metrics, confirming the benefit of task-adaptive λ. Increasing K to 0.20 yields similar efficiency (±2 %) and a further 4 % reduction in evaluation std.

External baselines. ASHA lags SACC by 38 % in evaluations-to-threshold on classic control and 24 % in area-under-curve on MuJoCo. TPE exhibits the highest evaluation-phase variance (+44 % vs SACC).

Cost analysis. Profiling shows 1.3 % ± 0.4 % increase in wall-clock time per evaluation, no change in peak VRAM, and identical FLOPs.

Threats to validity. Some MuJoCo settings use eight seeds due to cost; extreme tail fractions (>0.3) remain unexplored; all experiments use a single GPU type, leaving CPU-only scenarios untested.

---

---
Section: conclusion

Stability-Aware Curve Compression augments BOIL with a learned penalty on tail volatility, filling a critical gap in curve-centric Bayesian optimisation for deep RL. The modification preserves BOIL’s elegance—one scalar per run and three extra lines of code—yet delivers consistent, statistically significant gains: 22–31 % faster convergence, 5–14 % higher peak returns, ≈30 % lower reward variance, and negligible computational overhead. These improvements validate the hypothesis that late-phase stability is both measurable and exploitable within the BOIL framework.

SACC’s simplicity invites immediate adoption in existing BO pipelines and opens avenues for future research: richer robustness proxies (e.g., drawdown, change-point detection), dynamic tail selection, multi-objective acquisition balancing mean and variance, and hybrid models combining curve compression with partition-based HPO \cite{mlodozeniec-2023-hyperparameter}. Extending the evaluation protocol to larger benchmarks and higher-dimensional search spaces will further elucidate the conditions under which stability-aware compression yields the greatest benefit over vanilla BOIL \cite{nguyen-2019-bayesian}.

---


## LaTeX Formatting Rules:
- Use \subsection{...} for any subsections within this section.
    - Subsection titles should be distinct from the section name;
    - Do not use '\subsection{  }', or other slight variations. Use more descriptive and unique titles.
    - Avoid excessive subdivision. If a subsection is brief or overlaps significantly with another, consider merging them for clarity and flow.

- For listing contributions, use the LaTeX \begin{itemize}...\end{itemize} format.
    - Each item should start with a short title in \textbf{...} format.
    - Avoid using -, *, or other Markdown bullet styles.

- When including tables, use the `tabularx` environment with `\textwidth` as the target width.
    - At least one column must use the `X` type to enable automatic width adjustment and line breaking.
    - Include `\hline` at the top, after the header, and at the bottom. Avoid vertical lines unless necessary.
    - To left-align content in `X` columns, define `
ewcolumntype{Y}{>{
aggedrightrraybackslash}X}` using the `array` package.

- When writing pseudocode, use the `algorithm` and `algorithmicx` LaTeX environments.
    - Only include pseudocode in the `Method` section. Pseudocode is not allowed in any other sections.
    - Prefer the `\begin{algorithmic}` environment using **lowercase commands** such as `\State`, `\For`, and `\If`, to ensure compatibility and clean formatting.
    - Pseudocode must represent actual algorithms or procedures with clear logic. Do not use pseudocode to simply rephrase narrative descriptions or repeat what has already been explained in text.
        - Good Example:
        ```latex
        \State Compute transformed tokens: \(	ilde{T} \leftarrow W\,T\)
        \State Update: \(T_{new} \leftarrow 	ilde{T} + \mu\,T_{prev}\)
        ```
- Figures and images are ONLY allowed in the "Results" section.
    - Use LaTeX float option `[H]` to force placement.

- All figures must be inserted using the following LaTeX format, using a `width` that reflects the filename:
    ```latex
    \includegraphics[width=\linewidth]{ images/filename.pdf }
    ```
    The `<appropriate-width>` must be selected based on the filename suffix:
    - If the filename ends with _pair1.pdf or _pair2.pdf, use 0.48\linewidth as the width of each subfigure environment and place the figures side by side using `subcaption` package.
    - Otherwise (default), use 0.7\linewidth

- **Escaping special characters**:
    - LaTeX special characters (`#`, `$`, `%`, `&`, `~`, `_`, `^`, `{`, `}`, `\`) must be escaped with a leading backslash when they appear in plain text (e.g., `data\_set`, `C\&C`).
    - Underscores **must always be escaped** (`\_`) outside math mode, even in filenames (e.g., memory\_profiler), code-style words, itemize lists, or citation contexts.

- Always use ASCII hyphens (`-`) instead of en-dashes (`–`) or em-dashes (`—`) to avoid spacing issues in hyphenated terms.
- Do not include any of these higher-level commands such as \documentclass{...}, \begin{document}, and \end{document}.
    - Additionally, avoid including section-specific commands such as \begin{abstract}, \section{  }, or any other similar environment definitions.
- Do not modify citation placeholders:
    - Citation placeholders appear in the format [citation_key], where citation_key contains underscores, numbers, and text (e.g., [vaswani_2017_attention], [smith_2023_deep]).
    - You must preserve these placeholders EXACTLY as they appear in the input text.
- If no LaTeX conversion is needed, output the content as-is without status messages like [Unchanged].
Output:
{
    "title": "Stability-Aware Curve Compression for Bayesian Optimisation of Deep Reinforcement-Learning Hyper-parameters",
    "abstract": "Bayesian Optimisation for Iterative Learning (BOIL) compresses an entire learning curve into a single scalar through a sigmoid-weighted average that a Gaussian Process (GP) can model. While this summary accelerates hyper-parameter search, it ignores late-stage oscillations that are commonplace in deep reinforcement learning (RL). Consequently, BOIL may repeatedly invest evaluations in hyper-parameters that spike to high returns yet produce brittle policies. We propose Stability-Aware Curve Compression (SACC), a drop-in replacement for BOIL's scoring function that subtracts a stability penalty from the original score: \\(s = m(\\mathrm{curve}) - \\lambda \\cdot \\mathrm{std}(\\mathrm{tail})\\), where \\(m(\\mathrm{curve})\\) is the sigmoid-weighted mean, \\(\\mathrm{std}(\\mathrm{tail})\\) is the standard deviation of the last \\(K\\%\\) of episodes and \\(\\lambda \\ge 0\\) is a learnable coefficient. The amendment preserves BOIL's one-dimensional interface, adds three lines of code, and introduces a single additional parameter that is learned jointly with BOIL's logistic midpoint and growth by maximising GP log-marginal likelihood. On classic control and MuJoCo benchmarks SACC, evaluated over 10 random seeds, reduces the number of BO evaluations needed to reach task success by 22-31\\%, raises best-of-run returns by 5-14\\%, lowers evaluation-phase reward variance by roughly \\(\\approx 30\\%\\), and increases wall-clock cost by less than 2\\%. These results show that penalising tail volatility guides Bayesian optimisation toward robust hyper-parameters without sacrificing sample efficiency.",
    "introduction": "Hyper-parameter optimisation (HPO) remains a principal bottleneck in deep reinforcement learning because each evaluation entails thousands of expensive, high-variance environment interactions. Bayesian optimisation (BO) is attractive in this regime, but most BO variants treat performance as a terminal scalar, wasting information available in the trajectory of rewards accrued during training. Bayesian Optimisation for Iterative Learning (BOIL) alleviates this inefficiency by compressing partial learning curves into a scalar via a sigmoid-weighted average, allowing the GP surrogate and acquisition function to exploit intermediate progress \\cite{nguyen-2019-bayesian}. Unfortunately, a sole mean-like statistic hides a critical facet of solution quality: stability. Learning curves that climb to high rewards but oscillate heavily toward the end of training are unreliable at test time, yet BOIL, blind to volatility, may continue to query such regions of hyper-parameter space.\n\nWe address this reliability gap with Stability-Aware Curve Compression (SACC), a minimal modification of BOIL that rewards both progress and steadiness. After computing BOIL's sigmoid-weighted mean \\(m(\\mathrm{curve})\\), SACC subtracts a penalty proportional to the standard deviation of the last \\(K\\%\\) of episodes, producing a new score \\(s = m - \\lambda \\cdot \\sigma_{\\mathrm{tail}}\\). The penalty strength \\(\\lambda\\) is appended to BOIL's compression parameters and learned through GP marginal-likelihood maximisation, so no hand-tuning is required. Crucially, the score remains one-dimensional, leaving BOIL's surrogate, data augmentation, and acquisition optimisation intact.\n\nWhy is designing such a penalty hard? (i) Inflating the surrogate's output dimensionality would forfeit BOIL's computational advantage. (ii) Stability must be assessed cheaply because environment steps dominate cost. (iii) The penalty must adapt across tasks with disparate reward scales and noise characteristics. SACC satisfies these constraints by reusing BOIL's interface, computing one additional standard deviation, and letting \\(\\lambda\\) adjust automatically.\n\nWe empirically evaluate SACC on classic control tasks (CartPole-v1, LunarLander-v2, Acrobot-v1) and stochastic MuJoCo tasks (Hopper-v3, HalfCheetah-v3) under a unified protocol that measures five axes: sample efficiency, performance ceiling, stability, computational overhead, and generalisation. Baselines include vanilla BOIL \\cite{nguyen-2019-bayesian}, fixed-\\(\\lambda\\) ablations, and external HPO approaches such as multi-fidelity bandits and tree-structured Parzen estimators. Partition-based hyper-parameter optimisation methods that bypass BO surrogates \\cite{mlodozeniec-2023-hyperparameter} are also discussed for contrast but are not directly comparable because they neither exploit full curves nor target volatility.\n\n\\subsection{Contributions}\n\\begin{itemize}\n  \\item \\textbf{Reliability fix with minimal change} We uncover a reliability blind spot in BOIL and introduce SACC, a three-line drop-in fix that maintains BOIL's one-dimensional surrogate.\n  \\item \\textbf{Learnable stability coefficient} We integrate \\(\\lambda\\) as a learnable compression parameter, enabling task-adaptive stability control without manual tuning.\n  \\item \\textbf{Reusable evaluation protocol} We present a rigorous, reusable evaluation protocol focusing on efficiency, robustness, and cost.\n  \\item \\textbf{Empirical gains} Across six benchmarks and multiple noise regimes, we demonstrate 22-31\\% faster convergence, 5-14\\% higher best returns, \\(\\approx 30\\%\\) lower policy variance, and <2\\% runtime overhead.\n\\end{itemize}\n\nFuture work can extend SACC to richer one-dimensional robustness proxies, dynamic tail fractions, and hybrid schemes that blend curve compression with partition-based objectives.",
    "related_work": "Bayesian optimisation for hyper-parameter tuning traditionally relies on endpoint performance only. BOIL broke with this tradition by using a learnable sigmoid to weight intermediate rewards, markedly improving sample efficiency in neural network and RL settings \\cite{nguyen-2019-bayesian}. Our work adheres to BOIL's curve-centric philosophy but argues that a mean-style statistic is insufficient when late-stage volatility jeopardises policy reliability. By attaching an adaptive variance penalty, SACC retains BOIL's machinery while explicitly discouraging oscillatory trajectories.\n\nHyperparameter Optimisation through Neural Network Partitioning (HPO-NP) introduces a fundamentally different idea: optimise hyper-parameters via marginal-likelihood-inspired losses computed on subnetworks trained on data shards, eliminating the need for separate validation sets \\cite{mlodozeniec-2023-hyperparameter}. While effective for supervised learning, HPO-NP neither models the entire learning curve nor targets stability, and its reliance on differentiable objectives limits direct applicability to RL with sparse, delayed rewards.\n\nAlternative BO extensions include multi-fidelity methods that terminate unpromising runs early, density-estimation techniques such as TPE, and population-based bandits. These algorithms do not encode volatility awareness; any stability benefit is incidental. Empirically, our experiments show that such baselines trail BOIL+SACC in both sample efficiency and reward variance, highlighting the value of explicit stability awareness.\n\nCompared to prior work, SACC is unique in providing (i) a negligible-cost stability proxy that (ii) preserves the scalar surrogate interface and (iii) adapts automatically through GP marginal-likelihood learning, thereby offering a pragmatic and theoretically consistent refinement of curve-aware BO.",
    "background": "\\subsection{Problem setting}\nLet \\(x \\in \\mathcal{X}\\) denote a hyper-parameter vector; training an agent under \\(x\\) for \\(T\\) episodes yields a reward sequence \\(r_{1:T}\\). We seek to minimise the number of costly evaluations of \\(f(x)\\) while discovering \\(x\\) values whose induced policies achieve high, stable returns. BOIL defines \\(f(x)\\) as a sigmoid-weighted mean \\(m(x)=\\frac{1}{T} \\sum_{t} w_t r_t\\), where weights \\(w_t\\) depend on learnable midpoint \\(\\mu\\) and growth \\(g\\) parameters of a logistic. A Gaussian Process prior over \\(f\\) and an acquisition function then drive sequential search \\cite{nguyen-2019-bayesian}.\n\n\\subsection{Limitation of BOIL}\nBecause \\(m(x)\\) is essentially an average, it conflates smooth and erratic curves that share similar central tendencies. In deep RL, however, volatility often signals over-fitting to transient dynamics or premature value-function divergence-issues that manifest as poor generalisation or catastrophic drops once exploration noise is removed.\n\n\\subsection{Stability proxy}\nWe posit that the standard deviation of the tail-defined as the last \\(\\lceil K \\cdot T \\rceil\\) episodes-is an inexpensive yet informative measure of policy reliability. Using only the tail focuses on the period closest to deployment, ignoring early-phase exploration noise.\n\n\\subsection{Design principles}\n(i) One-dimensional compression keeps BOIL's computational benefits. (ii) Penalty computation must not require gradient access to the RL algorithm. (iii) The penalty weight \\(\\lambda\\) should be data-driven because reward scales vary by environment (CartPole \\(\\approx 200\\) vs HalfCheetah \\(>10{,}000\\)). SACC satisfies these principles by computing \\(\\sigma_{\\mathrm{tail}}\\) from logged rewards and learning \\(\\lambda\\) via GP marginal likelihood alongside \\(\\mu\\) and \\(g\\).",
    "method": "Given a reward trajectory \\(r_{1:T}\\), BOIL first maps episode indices to a scaled axis and computes weights \\(w_t = \\frac{1}{1+\\exp(-g (s_t - \\mu))}\\). The original score is \\(m = \\frac{1}{T} \\sum_{t} w_t r_t\\). Stability-Aware Curve Compression augments this by\n\\begin{enumerate}\n  \\item Selecting the tail: \\(k = \\max(1, \\lceil K \\cdot T \\rceil)\\). Tail rewards are \\(r_{T-k+1:T}\\).\n  \\item Computing volatility: \\(\\sigma_{\\mathrm{tail}} = \\mathrm{std}(r_{T-k+1:T})\\).\n  \\item Producing the score: \\(s = m - \\lambda \\, \\sigma_{\\mathrm{tail}}\\), with \\(\\lambda \\ge 0\\).\n\\end{enumerate}\n\nAlgorithmic integration. We simply replace BOIL's apply\\_one\\_transform\\_logistic with a three-line variant that computes a sigmoid-weighted mean and subtracts a scaled tail standard deviation.\n\n\\begin{algorithm}\n\\caption{Compute SACC score for a learning curve}\n\\begin{algorithmic}[1]\n\\State \\textbf{Input:} rewards \\(r_{1:T}\\); sigmoid params \\(\\mu, g\\); tail fraction \\(K\\); penalty weight \\(\\lambda \\ge 0\\)\n\\State \\textbf{Output:} scalar score \\(s\\)\n\\State Map episode indices to scaled axis values \\(s_t\\)\n\\State Compute weights: \\(w_t \\leftarrow \\frac{1}{1+\\exp(-g (s_t - \\mu))}\\) for \\(t=1,\\dots,T\\)\n\\State Sigmoid-weighted mean: \\(m \\leftarrow \\frac{1}{T} \\sum_{t=1}^{T} w_t r_t\\)\n\\State Tail length: \\(k \\leftarrow \\max(1, \\lceil K \\cdot T \\rceil)\\)\n\\State Tail rewards: \\(\\{r_{T-k+1},\\dots,r_T\\}\\)\n\\State Tail volatility: \\(\\sigma_{\\mathrm{tail}} \\leftarrow \\mathrm{std}(\\{r_{T-k+1},\\dots,r_T\\})\\)\n\\State Score: \\(s \\leftarrow m - \\lambda \\, \\sigma_{\\mathrm{tail}}\\)\n\\State \\Return \\(s\\)\n\\end{algorithmic}\n\\end{algorithm}\n\nParameter learning. The vector \\(\\theta = (\\mu, g, \\lambda)\\) maximises the GP log-marginal likelihood over observed pairs \\((x_i, s_i)\\). We bound \\(\\lambda\\) and initialise at 1.0. Acquisition, data augmentation across partial curves, and GP kernel choices remain identical to BOIL.\n\nComputational overhead. \\(\\sigma_{\\mathrm{tail}}\\) uses at most \\(k\\) additional floating-point operations per evaluation-negligible relative to millions of environment steps. Because \\(s\\) remains scalar, GP regression complexity is unchanged.",
    "experimental_setup": "\\subsection{Unified protocol}\nTo facilitate fair comparison and future replication, we employ a standardised five-step procedure: (1) Fix task-specific success thresholds and hyper-parameter search spaces. (2) Generate an identical random initial design of five configurations for all methods. (3) Run BO for a fixed budget \\(B\\) evaluations (25 for classic control, 40 for MuJoCo), logging full learning curves. (4) Retrain the best configuration from each run for an extended horizon, collecting 20-50 evaluation episodes. (5) Aggregate metrics across 10 random seeds (8 for MuJoCo) and conduct paired statistical tests.\n\n\\subsection{Tasks and search spaces}\nClassic control (CartPole-v1, LunarLander-v2, Acrobot-v1) tune two DQN hyper-parameters: learning rate and target-network update period. MuJoCo tasks (Hopper-v3, HalfCheetah-v3) extend the space to up to seven parameters, adding optimiser momentum, exploration \\(\\varepsilon\\), and discount \\(\\gamma\\).\n\n\\subsection{Methods}\nWe compare (i) vanilla BOIL \\cite{nguyen-2019-bayesian}; (ii) BOIL+SACC (ours); (iii) fixed-\\(\\lambda\\) ablations (\\(\\lambda \\in \\{0.5, 1, 2, 4\\}\\)); (iv) multi-fidelity Asynchronous Successive Halving (ASHA); (v) Tree-Structured Parzen Estimator (TPE). All methods share the same RL implementation, seeds, and hardware.\n\n\\subsection{Hyper-parameters for SACC}\nTail fraction \\(K = 0.10\\) by default; sensitivity analysis tests \\(K = 0.20\\). \\(\\lambda\\) is learned with bounds. All other GP and acquisition settings mirror BOIL defaults.\n\n\\subsection{Metrics}\nPrimary: (1) evaluations-to-threshold; (2) best validation reward after \\(B\\) evaluations. Secondary: (3) area under the best-return curve; (4) \\(\\sigma_{\\mathrm{tail}}\\); (5) evaluation-phase reward mean \\(\\pm\\) std; (6) wall-clock and memory usage. Significance is assessed with paired t-tests or Wilcoxon tests at \\(p < 0.05\\).",
    "results": "\\subsection{Main study: classic control}\nBOIL+SACC reaches the success threshold in fewer evaluations: CartPole-v1 \\(12.1 \\pm 1.0\\) vs \\(17.3 \\pm 1.2\\) for BOIL (-30\\%, \\(p=8\\times 10^{-4}\\)); LunarLander-v2 \\(16.2 \\pm 1.3\\) vs \\(21.6 \\pm 1.5\\) (-25\\%, \\(p=3\\times 10^{-3}\\)); Acrobot-v1 \\(14.0 \\pm 1.1\\) vs \\(19.4 \\pm 1.4\\) (-28\\%, \\(p=2\\times 10^{-3}\\)). Best-of-run returns improve by 3-5\\% (CartPole +6.6, LunarLander +11.4, Acrobot +13.2). Training-curve volatility falls by 31\\% on average; evaluation-phase reward std drops by 51\\% (CartPole) and 33\\% (LunarLander). Area-under-curve gains average 21\\%.\n\n\\subsection{Robustness study: MuJoCo, high variance}\nWith a 40-evaluation budget, SACC outpaces BOIL: Hopper-v3 threshold at 28.2 vs 36.1 evaluations (-22\\%, \\(p=0.01\\)); HalfCheetah-v3 29.4 vs 37.2 (-21\\%, \\(p=0.02\\)). Best-of-run returns rise by \\(\\approx 5\\%\\). Evaluation-phase std decreases by 31\\% (Hopper) and 28\\% (HalfCheetah). Under gravity-shift stress, SACC's performance degrades by 12\\% vs 22\\% for BOIL.\n\n\\subsection{Ablations}\nFixed-\\(\\lambda\\) variants outperform vanilla BOIL but underperform learned-\\(\\lambda\\) SACC on all primary metrics, confirming the benefit of task-adaptive \\(\\lambda\\). Increasing \\(K\\) to 0.20 yields similar efficiency (\\(\\pm 2\\%\\)) and a further 4\\% reduction in evaluation std.\n\n\\subsection{External baselines}\nASHA lags SACC by 38\\% in evaluations-to-threshold on classic control and 24\\% in area-under-curve on MuJoCo. TPE exhibits the highest evaluation-phase variance (+44\\% vs SACC).\n\n\\subsection{Cost analysis}\nProfiling shows \\(1.3\\% \\pm 0.4\\%\\) increase in wall-clock time per evaluation, no change in peak VRAM, and identical FLOPs.\n\n\\subsection{Threats to validity}\nSome MuJoCo settings use eight seeds due to cost; extreme tail fractions (>0.3) remain unexplored; all experiments use a single GPU type, leaving CPU-only scenarios untested.",
    "conclusion": "Stability-Aware Curve Compression augments BOIL with a learned penalty on tail volatility, filling a critical gap in curve-centric Bayesian optimisation for deep RL. The modification preserves BOIL's elegance-one scalar per run and three extra lines of code-yet delivers consistent, statistically significant gains: 22-31\\% faster convergence, 5-14\\% higher peak returns, \\(\\approx 30\\%\\) lower reward variance, and negligible computational overhead. These improvements validate the hypothesis that late-phase stability is both measurable and exploitable within the BOIL framework.\n\nSACC's simplicity invites immediate adoption in existing BO pipelines and opens avenues for future research: richer robustness proxies (e.g., drawdown, change-point detection), dynamic tail selection, multi-objective acquisition balancing mean and variance, and hybrid models combining curve compression with partition-based HPO \\cite{mlodozeniec-2023-hyperparameter}. Extending the evaluation protocol to larger benchmarks and higher-dimensional search spaces will further elucidate the conditions under which stability-aware compression yields the greatest benefit over vanilla BOIL \\cite{nguyen-2019-bayesian}."
}
